{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "name": "5_My. Моделирование языка с помощью Transformer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxjNjpGrpyEJ"
      },
      "source": [
        "# Language modeling using transformer on Hermann Hesse bibliography data (in Russian)\r\n",
        "\r\n",
        "### Based on course [\"Нейронные сети и обработка текста\"](https://stepik.org/course/54098/)\r\n",
        "\r\n",
        "If you are going to read this notebook, I recommend you to open it in [google colab](https://colab.research.google.com/notebooks/intro.ipynb#recent=true) and start reading from [the beginning of the analysis](#scrollTo=fxTodB_qpyEX), using the attached hyperlinks on functions and classes if you need to."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "189TS3fH2Cv5"
      },
      "source": [
        "## Required libraries, functions and classes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dH0NvW8BzsGf"
      },
      "source": [
        "!pip3 install pytorch-nlp --quiet\r\n",
        "!pip3 install youtokentome --quiet\r\n",
        "!pip3 install livelossplot --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:27:53.780539Z",
          "start_time": "2019-11-05T18:27:52.444607Z"
        },
        "id": "3UMrCkoppyEW"
      },
      "source": [
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "\n",
        "import sys\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn import functional as F\n",
        "from torchnlp.word_to_vector import BPEmb\n",
        "\n",
        "import youtokentome as yttm\n",
        "\n",
        "import random\n",
        "\n",
        "import heapq\n",
        "\n",
        "from livelossplot import PlotLosses\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import datetime\n",
        "\n",
        "from traceback import format_exc\n",
        "\n",
        "from copy import deepcopy"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyGXXxapuloL"
      },
      "source": [
        "def init_random_seed(value=0):\r\n",
        "    random.seed(value)\r\n",
        "    np.random.seed(value)\r\n",
        "    torch.manual_seed(value)\r\n",
        "    torch.cuda.manual_seed(value)\r\n",
        "    torch.backends.cudnn.deterministic = True\r\n",
        "\r\n",
        "init_random_seed()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbJvwqUvq4Gb"
      },
      "source": [
        "def copy_data_to_device(data, device):\r\n",
        "    if torch.is_tensor(data):\r\n",
        "        return data.to(device)\r\n",
        "    elif isinstance(data, (list, tuple)):\r\n",
        "        return [copy_data_to_device(elem, device) for elem in data]\r\n",
        "    raise ValueError('Invalid data type {}'.format(type(data)))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oj68ZM-IwWiK"
      },
      "source": [
        "def get_params_number(model):\r\n",
        "    return sum(t.numel() for t in model.parameters())"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fz6D2ry6q2Ly"
      },
      "source": [
        "def divisors(n):\r\n",
        "    \"\"\"Find all divisors of a number\"\"\"\r\n",
        "    i = 1\r\n",
        "    divisors = []\r\n",
        "    while i <= n**0.5:\r\n",
        "        if (n % i == 0) : \r\n",
        "            if (n / i == i):\r\n",
        "                divisors.append(i)\r\n",
        "            else:\r\n",
        "                divisors.extend([i, n // i])\r\n",
        "        i = i + 1\r\n",
        "    return sorted(divisors)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_LSDUa9ufKL"
      },
      "source": [
        "def split_into_chunks(filename, chunk_size=200):\r\n",
        "    with open(filename) as f:\r\n",
        "        full_text = f.read()\r\n",
        "    return [full_text[start:start + chunk_size] for start in range(0, len(full_text), chunk_size // 2)]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYs7y8NkMDFJ"
      },
      "source": [
        "def ensure_length(txt, out_len, pad_value):\r\n",
        "    if len(txt) < out_len:\r\n",
        "        txt = list(txt) + [pad_value] * (out_len - len(txt))\r\n",
        "    else:\r\n",
        "        txt = txt[:out_len]\r\n",
        "    return txt\r\n",
        "\r\n",
        "class LanguageModelDataset(Dataset):\r\n",
        "    def __init__(self, sample, chunk_length=100, pad_value=0):\r\n",
        "        self.sample = sample\r\n",
        "        self.chunk_length = chunk_length\r\n",
        "        self.pad_value = pad_value\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.sample)\r\n",
        "\r\n",
        "    def __getitem__(self, item):\r\n",
        "        text = self.sample[item]\r\n",
        "        start_i = random.randint(0, max(0, len(text) - self.chunk_length - 1))\r\n",
        "        chunk = text[start_i : start_i + self.chunk_length + 1]\r\n",
        "\r\n",
        "        seed_part = chunk[:-1]\r\n",
        "        target_part = chunk[1:]\r\n",
        "\r\n",
        "        seed_part = ensure_length(seed_part, self.chunk_length, self.pad_value)\r\n",
        "        target_part = ensure_length(target_part, self.chunk_length, self.pad_value)\r\n",
        "\r\n",
        "        seed_part = np.array(seed_part)\r\n",
        "        target_part = np.array(target_part)\r\n",
        "\r\n",
        "        return seed_part, target_part"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTe72xVdPHil"
      },
      "source": [
        "def make_target_dependency_mask(length):\r\n",
        "    full_mask = torch.ones(length, length)\r\n",
        "    ignore_mask = torch.tril(full_mask) < 1\r\n",
        "    full_mask.masked_fill_(ignore_mask, float('-inf'))\r\n",
        "    full_mask.masked_fill_(~ignore_mask, 0)\r\n",
        "    return full_mask"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phSORpvwZdn4"
      },
      "source": [
        "def make_positional_encoding(max_length, embedding_size):\r\n",
        "    time = np.pi * torch.arange(0, max_length).float()\r\n",
        "    freq_dividers = torch.arange(1, embedding_size // 2 + 1).float()\r\n",
        "    inputs = time[:, None] / freq_dividers[None, :]\r\n",
        "    result = torch.zeros(max_length, embedding_size)\r\n",
        "    result[:, 0::2] = torch.sin(inputs)\r\n",
        "    result[:, 1::2] = torch.cos(inputs)\r\n",
        "    return result"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZBmKyALZ5lq"
      },
      "source": [
        "class LanguageModel(nn.Module):\r\n",
        "    \"\"\" General class. param::backbone - used architecture of NNet \"\"\"\r\n",
        "    def __init__(self, vocab_size, emb_size, backbone, emb_weights=None, freeze=True, emb_dropout=0.0):\r\n",
        "        super().__init__()\r\n",
        "        if emb_weights is not None:\r\n",
        "            self.embeddings = nn.Embedding.from_pretrained(emb_weights, freeze=freeze, padding_idx=0)\r\n",
        "        else:\r\n",
        "            self.embeddings = nn.Embedding(vocab_size, emb_size, padding_idx=0)\r\n",
        "        self.embedding_size = emb_size\r\n",
        "        self.emb_dropout = nn.Dropout(emb_dropout)\r\n",
        "        self.backbone = backbone\r\n",
        "        self.out = nn.Linear(emb_size, vocab_size)\r\n",
        "    \r\n",
        "    def forward(self, seed_tokenized_sample):\r\n",
        "        batch_size, max_in_length = seed_tokenized_sample.shape\r\n",
        "\r\n",
        "        seed_padding_mask = seed_tokenized_sample == 0\r\n",
        "        dependency_mask = make_target_dependency_mask(max_in_length).to(seed_tokenized_sample.device)\r\n",
        "        \r\n",
        "        seed_embs = self.embeddings(seed_tokenized_sample)  # BatchSize x MaxInLen x EmbSize\r\n",
        "        pos_codes = make_positional_encoding(max_in_length, self.embedding_size).unsqueeze(0).to(seed_embs.device) # 1 x MaxInLen x EmbSize\r\n",
        "        seed_embs = seed_embs + pos_codes\r\n",
        "        seed_embs = self.emb_dropout(seed_embs)\r\n",
        "\r\n",
        "        # BatchSize x TargetLen x EmbSize\r\n",
        "        target_features = self.backbone(seed_embs,\r\n",
        "                                        mask=dependency_mask,\r\n",
        "                                        src_key_padding_mask=seed_padding_mask)\r\n",
        "        logits = self.out(target_features)  # BatchSize x TargetLen x VocabSize\r\n",
        "        return logits"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ffXvcbUdnOl"
      },
      "source": [
        "def lm_cross_entropy(pred, target):\r\n",
        "    \"\"\"\r\n",
        "    pred - BatchSize x TargetLen x VocabSize\r\n",
        "    target - BatchSize x TargetLen\r\n",
        "    \"\"\"\r\n",
        "    pred_flat = pred.view(-1, pred.shape[-1])  # BatchSize*TargetLen x VocabSize\r\n",
        "    target_flat = target.view(-1)  # BatchSize*TargetLen\r\n",
        "    return F.cross_entropy(pred_flat, target_flat, ignore_index=0)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYH07KJVd4n0"
      },
      "source": [
        "class BatchFirstTransformerEncoder(nn.Module):\r\n",
        "    def __init__(self, *args, **kwargs):\r\n",
        "        super().__init__()\r\n",
        "        self.impl = nn.TransformerEncoder(*args, **kwargs)\r\n",
        "        self.initialize_weights()\r\n",
        "    \r\n",
        "    def forward(self, src, *args, **kwargs):\r\n",
        "        src = src.transpose(0, 1).contiguous()  # MaxInLen x BatchSize x EmbSize\r\n",
        "        result = self.impl(src, *args, **kwargs)  # TargetLen x BatchSize x EmbSize\r\n",
        "        result = result.transpose(0, 1).contiguous()  # BatchSize x TargetLen x EmbSize\r\n",
        "        return result\r\n",
        "    \r\n",
        "    def initialize_weights(self):\r\n",
        "        for param in self.impl.parameters():\r\n",
        "            if param.dim() > 1:\r\n",
        "                nn.init.xavier_uniform_(param)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jx44W288jjRP"
      },
      "source": [
        "def train_eval_loop(model, train_dataset, val_dataset, criterion, lr=1e-3, epoch_n=100, batch_size_train=32,\r\n",
        "                    batch_size_val=32, device=None, early_stopping_patience=10, l2_reg_alpha=0, data_loader_ctor=DataLoader,\r\n",
        "                    optimizer_ctor=None, lr_scheduler_ctor=None, dataloader_workers_n=0, draw_loss=False, show_bar=False, show_lr=False):\r\n",
        "\r\n",
        "\r\n",
        "    assert len(train_dataset) % batch_size_train == 0, \"len of train_dataset must be divisible by train_batch_size\"\r\n",
        "    assert len(val_dataset) % batch_size_val == 0, \"len of val_dataset must be divisible by val_batch_size\"\r\n",
        "\r\n",
        "    if device is None:\r\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n",
        "    device = torch.device(device)\r\n",
        "    model.to(device)\r\n",
        "\r\n",
        "    if optimizer_ctor is None:\r\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2_reg_alpha)\r\n",
        "    else:\r\n",
        "        optimizer = optimizer_ctor(model.parameters(), lr=lr)\r\n",
        "    \r\n",
        "    if lr_scheduler_ctor is not None:\r\n",
        "        lr_scheduler = lr_scheduler_ctor(optimizer)\r\n",
        "    else:\r\n",
        "        lr_scheduler = None\r\n",
        "\r\n",
        "    if draw_loss:\r\n",
        "        liveplot = PlotLosses()\r\n",
        "    \r\n",
        "    train_dataloader = data_loader_ctor(train_dataset, batch_size=batch_size_train, num_workers=dataloader_workers_n)\r\n",
        "    val_dataloader = data_loader_ctor(val_dataset, batch_size=batch_size_val, num_workers=dataloader_workers_n)\r\n",
        "\r\n",
        "    best_val_loss = float(\"inf\")\r\n",
        "    best_epoch_i = 0\r\n",
        "    best_model = deepcopy(model)\r\n",
        "    \r\n",
        "    for epoch_i in range(epoch_n):\r\n",
        "        try:\r\n",
        "            if not draw_loss:\r\n",
        "                epoch_start = datetime.datetime.now()\r\n",
        "                print(f\"Epoch {epoch_i}\")\r\n",
        "\r\n",
        "            model.train()\r\n",
        "            mean_train_loss = 0\r\n",
        "            train_batches_n = 0\r\n",
        "\r\n",
        "            for batch_i, (batch_x, batch_y) in enumerate(tqdm(train_dataloader)) if show_bar else enumerate(train_dataloader):\r\n",
        "                batch_x = copy_data_to_device(batch_x, device)\r\n",
        "                batch_y = copy_data_to_device(batch_y, device)\r\n",
        "\r\n",
        "                pred = model(batch_x)\r\n",
        "                loss = criterion(pred, batch_y)\r\n",
        "\r\n",
        "                model.zero_grad()\r\n",
        "                loss.backward()\r\n",
        "\r\n",
        "                optimizer.step()\r\n",
        "\r\n",
        "                mean_train_loss += float(loss)\r\n",
        "                train_batches_n += 1\r\n",
        "\r\n",
        "\r\n",
        "            mean_train_loss /= train_batches_n\r\n",
        "\r\n",
        "            model.eval()\r\n",
        "            mean_val_loss = 0\r\n",
        "            val_batches_n = 0\r\n",
        "\r\n",
        "            with torch.no_grad():\r\n",
        "                for batch_i, (batch_x, batch_y) in enumerate(val_dataloader):\r\n",
        "\r\n",
        "                    batch_x = copy_data_to_device(batch_x, device)\r\n",
        "                    batch_y = copy_data_to_device(batch_y, device)\r\n",
        "\r\n",
        "                    pred = model(batch_x)\r\n",
        "                    loss = criterion(pred, batch_y)\r\n",
        "\r\n",
        "                    mean_val_loss += float(loss)\r\n",
        "                    val_batches_n += 1\r\n",
        "\r\n",
        "            mean_val_loss /= val_batches_n\r\n",
        "\r\n",
        "            if not draw_loss:\r\n",
        "                print('{} iterations for training and {} for validation, {:0.2f} sec'.format(train_batches_n, val_batches_n,\r\n",
        "                                                           (datetime.datetime.now() - epoch_start).total_seconds()))\r\n",
        "                print('Average value of the train loss function:', mean_train_loss)\r\n",
        "                print('Average value of the validation loss function:', mean_val_loss)\r\n",
        "            else:\r\n",
        "                liveplot.update({'mean loss': mean_train_loss, \"val_mean loss\": mean_val_loss})\r\n",
        "                liveplot.draw()\r\n",
        "\r\n",
        "            if mean_val_loss < best_val_loss:\r\n",
        "                best_epoch_i = epoch_i\r\n",
        "                best_val_loss = mean_val_loss\r\n",
        "                best_model = deepcopy(model)\r\n",
        "                if not draw_loss:\r\n",
        "                    print('New best model!')\r\n",
        "            elif epoch_i - best_epoch_i > early_stopping_patience:\r\n",
        "                print('The model has not improved over the last {} epochs, stop training'.format(\r\n",
        "                    early_stopping_patience))\r\n",
        "                break\r\n",
        "  \r\n",
        "            if lr_scheduler is not None:\r\n",
        "                if isinstance(lr_scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\r\n",
        "                    lr_scheduler.step(mean_val_loss)\r\n",
        "                elif isinstance(lr_scheduler, torch.optim.lr_scheduler.StepLR):\r\n",
        "                    lr_scheduler.step()\r\n",
        "                    if show_lr:\r\n",
        "                        print(optimizer.param_groups[0]['lr'])\r\n",
        "                else:\r\n",
        "                    lr_scheduler.step()\r\n",
        "\r\n",
        "            print()\r\n",
        "        except KeyboardInterrupt:\r\n",
        "            print('Stopped early by user')\r\n",
        "            break\r\n",
        "        except Exception as ex:\r\n",
        "            print('Error while training: {}\\n{}'.format(ex, format_exc()))\r\n",
        "            break\r\n",
        "\r\n",
        "    return best_val_loss, best_model"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqx_G7G2f2Bd"
      },
      "source": [
        "class GreedyGenerator:\r\n",
        "    def __init__(self, model, tokenizer, device='cuda', eos_token_id=3):\r\n",
        "        self.model = model\r\n",
        "        self.tokenizer = tokenizer\r\n",
        "        self.device = torch.device(device)\r\n",
        "        self.model.to(self.device)\r\n",
        "        self.eos_token_id = eos_token_id\r\n",
        "\r\n",
        "    def __call__(self, seed_text, max_steps_n=40):\r\n",
        "        seed_tokens = self.tokenizer.encode([seed_text])[0]\r\n",
        "\r\n",
        "        for _ in range(max_steps_n):\r\n",
        "            in_batch = torch.tensor(seed_tokens).unsqueeze(0).to(self.device)\r\n",
        "            best_next_token = self.model(in_batch)[0, -1].argmax()\r\n",
        "            if best_next_token == self.eos_token_id:\r\n",
        "                break\r\n",
        "\r\n",
        "            seed_tokens.append(best_next_token)\r\n",
        "\r\n",
        "        return self.tokenizer.decode([seed_tokens])[0]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rt4J8aX4-AMJ"
      },
      "source": [
        "class BeamGenerator:\r\n",
        "    def __init__(self, model, tokenizer, device='cuda', eos_token_id=3):\r\n",
        "        self.model = model\r\n",
        "        self.tokenizer = tokenizer\r\n",
        "        self.device = torch.device(device)\r\n",
        "        self.model.to(self.device)\r\n",
        "        self.eos_token_id = eos_token_id\r\n",
        "\r\n",
        "    def __call__(self, seed_text, max_steps_n=40, return_hypotheses_n=5, beamsize=5):\r\n",
        "        seed_tokens = self.tokenizer.encode([seed_text])[0]\r\n",
        "        initial_length = len(seed_tokens)\r\n",
        "\r\n",
        "        partial_hypotheses = [(0, seed_tokens)]\r\n",
        "        final_hypotheses = []\r\n",
        "\r\n",
        "        while len(partial_hypotheses) > 0:\r\n",
        "            cur_partial_score, cur_partial_hypothesis = heapq.heappop(partial_hypotheses)\r\n",
        "\r\n",
        "            in_batch = torch.tensor(cur_partial_hypothesis).unsqueeze(0).to(self.device)\r\n",
        "            next_tokens_logits = self.model(in_batch)[0, -1]\r\n",
        "            next_tokens_logproba = F.log_softmax(next_tokens_logits, dim=0)\r\n",
        "            topk_continuations = next_tokens_logproba.topk(beamsize)\r\n",
        "\r\n",
        "            for token_score, token_idx in zip(topk_continuations.values, topk_continuations.indices):\r\n",
        "                token_score = float(token_score)\r\n",
        "                token_idx = int(token_idx)\r\n",
        "\r\n",
        "                old_denorm_score = cur_partial_score * np.sqrt(len(cur_partial_hypothesis))\r\n",
        "                new_score = (old_denorm_score - token_score) / np.sqrt(len(cur_partial_hypothesis) + 1)\r\n",
        "\r\n",
        "                new_hypothesis = cur_partial_hypothesis + [token_idx]\r\n",
        "                new_item = (new_score, new_hypothesis)\r\n",
        "\r\n",
        "                if token_idx == self.eos_token_id or len(new_hypothesis) - initial_length >= max_steps_n:\r\n",
        "                    final_hypotheses.append(new_item)\r\n",
        "                else:\r\n",
        "                    heapq.heappush(partial_hypotheses, new_item)\r\n",
        "\r\n",
        "            if len(partial_hypotheses) > beamsize:\r\n",
        "                partial_hypotheses = heapq.nsmallest(beamsize, partial_hypotheses)\r\n",
        "                heapq.heapify(partial_hypotheses)\r\n",
        "\r\n",
        "        final_scores, final_token_lists = zip(*final_hypotheses)\r\n",
        "        final_texts = self.tokenizer.decode(list(final_token_lists))\r\n",
        "\r\n",
        "        result = list(zip(final_scores, final_texts))\r\n",
        "        result.sort()\r\n",
        "        result = result[:return_hypotheses_n]\r\n",
        "\r\n",
        "        return result"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rU5MrlzEygY"
      },
      "source": [
        "class ProbGenerator:\r\n",
        "    def __init__(self, model, tokenizer, device='cuda', eos_token_id=3, max_steps_n=40, temperature=1.0):\r\n",
        "        self.model = model\r\n",
        "        self.tokenizer = tokenizer\r\n",
        "        self.device = torch.device(device)\r\n",
        "        self.model.to(self.device)\r\n",
        "        self.eos_token_id = eos_token_id\r\n",
        "        self.max_steps_n = max_steps_n\r\n",
        "        self.temperature = temperature\r\n",
        "\r\n",
        "    def __call__(self, seed_text):\r\n",
        "        seed_tokens = self.tokenizer.encode([seed_text])[0]\r\n",
        "        \r\n",
        "        with torch.no_grad():\r\n",
        "            for _ in range(self.max_steps_n):\r\n",
        "                in_batch = torch.tensor(seed_tokens).unsqueeze(0).to(self.device)\r\n",
        "                logits_next = self.model(in_batch)[0, -1]\r\n",
        "                p_next = F.softmax(logits_next / self.temperature, dim=-1).data.cpu().numpy()\r\n",
        "                next_token = np.random.choice(len(tokenizer.vocab()), p=p_next)\r\n",
        "                if next_token == self.eos_token_id:\r\n",
        "                    break\r\n",
        "                seed_tokens.append(next_token)\r\n",
        "\r\n",
        "        return ''.join(self.tokenizer.decode([seed_tokens], ignore_ids=[0,2,3]))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxTodB_qpyEX"
      },
      "source": [
        "## Loading dataset and splitting it into training and test samples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BONUO-4xjwZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abdf36db-5695-4576-b2ea-c85bbfc749d0"
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kboz1dTKxaCh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b221093-a2af-47e1-82b1-283fcc4d2339"
      },
      "source": [
        "dataset_filename = \"/content/gdrive/My Drive/ML/datasets/Hermann_Hesse_bibliography_ru.txt\"\r\n",
        "all_chunks = split_into_chunks(dataset_filename, chunk_size=500)\r\n",
        "len(all_chunks)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17067"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:27:55.954154Z",
          "start_time": "2019-11-05T18:27:55.919185Z"
        },
        "id": "nL1MgC8NpyEY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6761343-603c-4830-d61e-8631bf5f8149"
      },
      "source": [
        "np.random.shuffle(all_chunks)\n",
        "\n",
        "TRAIN_SPLIT = int(len(all_chunks) * 0.7)\n",
        "train_sample = all_chunks[:TRAIN_SPLIT]\n",
        "val_sample = all_chunks[TRAIN_SPLIT:]\n",
        "\n",
        "print(\"Training sample size:\", len(train_sample))\n",
        "print(\"Validation sample size:\", len(val_sample))\n",
        "\n",
        "# Save train sample in file for further BPE training:\n",
        "TRAIN_SAMPLE_FILENAME = \"/tmp/train_sample.txt\"\n",
        "\n",
        "with open(TRAIN_SAMPLE_FILENAME, 'w') as f:\n",
        "    f.write('\\n'.join(train_sample))\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training sample size: 11946\n",
            "Validation sample size: 5121\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_pCUk_kpyEZ"
      },
      "source": [
        "##  BPE tokenization using [youtokentome library](https://pypi.org/project/youtokentome/):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veO9baR95w4R"
      },
      "source": [
        "NUM_TOKENS_BPE = 500\r\n",
        "BPE_MODEL_FILENAME = \"/tmp/bpe_model.yttm\"\r\n",
        "yttm.BPE.train(data=TRAIN_SAMPLE_FILENAME, vocab_size=NUM_TOKENS_BPE, model=BPE_MODEL_FILENAME)\r\n",
        "\r\n",
        "tokenizer = yttm.BPE(BPE_MODEL_FILENAME)\r\n",
        "\r\n",
        "train_tokenized_sample = tokenizer.encode(train_sample, bos=True, eos=True)\r\n",
        "val_tokenized_sample = tokenizer.encode(val_sample, bos=True, eos=True)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFenMS90ghZU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63e37acf-6948-42cf-870f-ee5be986d3b3"
      },
      "source": [
        "print(train_tokenized_sample[0])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2, 4, 12, 18, 212, 326, 346, 12, 150, 157, 192, 18, 267, 150, 239, 297, 25, 159, 333, 195, 29, 214, 28, 152, 229, 245, 174, 326, 240, 13, 23, 18, 195, 29, 214, 28, 209, 332, 350, 334, 193, 174, 156, 191, 14, 324, 15, 195, 29, 214, 28, 31, 4, 93, 414, 407, 278, 380, 27, 355, 155, 410, 231, 403, 244, 18, 305, 422, 6, 169, 160, 259, 440, 152, 227, 194, 219, 465, 164, 29, 319, 211, 193, 175, 372, 20, 443, 165, 233, 470, 437, 247, 33, 155, 343, 175, 9, 293, 396, 407, 33, 31, 282, 18, 255, 264, 18, 274, 16, 164, 11, 408, 417, 357, 200, 18, 315, 191, 155, 4, 64, 5, 164, 18, 224, 211, 197, 161, 212, 381, 332, 326, 346, 12, 296, 174, 374, 157, 420, 154, 18, 296, 174, 156, 496, 380, 186, 35, 18, 296, 174, 156, 496, 165, 319, 54, 385, 166, 294, 12, 18, 209, 212, 333, 372, 20, 443, 176, 194, 150, 190, 13, 185, 246, 151, 22, 12, 200, 15, 4, 33, 9, 35, 5, 246, 387, 28, 337, 4, 14, 23, 21, 157, 180, 158, 172, 202, 304, 203, 259, 204, 152, 164, 226, 15, 326, 25, 215, 18, 166, 294, 12, 18, 209, 372, 20, 443, 212, 232, 21, 13, 242, 12, 155, 455, 164, 310, 235, 198, 415, 433, 247, 364, 21, 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:27:57.897826Z",
          "start_time": "2019-11-05T18:27:57.874631Z"
        },
        "id": "DYo6GFY3pyEb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b261ce2d-89e7-405d-d45d-eeef411830b0"
      },
      "source": [
        "print(tokenizer.vocab())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<PAD>', '<UNK>', '<BOS>', '<EOS>', '▁', 'о', 'е', 'а', 'и', 'н', 'т', 'с', 'л', 'в', 'р', 'м', 'к', 'д', ',', 'у', 'п', 'я', 'ы', 'ь', 'г', 'б', 'з', 'ч', 'й', 'ж', 'х', '.', 'ш', 'ю', 'щ', 'ц', 'э', '—', '\\xa0', '-', 'Н', 'О', 'В', 'К', 'ф', 'П', 'И', 'Т', '?', 'С', 'Г', 'М', ':', 'Я', '!', '–', 'Д', ';', 'Б', 'А', '«', '»', 'Э', 'Е', 'Л', 'Р', 'З', 'Ч', 'У', '1', 'ъ', '(', ')', ']', '[', 'Ф', 'Х', 'i', 'e', '8', 'a', 's', 'u', '9', 'Ш', '…', 'r', 'o', '7', 't', '2', '4', '6', 'Ж', '3', '0', '5', 'Ц', 'n', 'm', 'I', 'l', 'c', 'Ю', 'X', 'd', 'ё', 'g', 'V', 'v', 'p', 'h', 'b', 'L', '“', '„', 'f', 'C', 'Й', 'q', 'Ь', 'x', \"'\", 'M', 'A', 'Ы', 'E', 'T', 'D', 'B', 'y', 'P', 'J', '’', 'Щ', 'S', 'F', 'w', 'k', 'R', 'z', 'U', 'N', 'K', 'H', 'j', 'Q', '№', 'W', 'G', '▁с', '▁п', '▁в', '▁н', 'то', '▁и', '▁о', 'но', 'ст', 'ен', 'ко', 'го', 'ал', '▁м', 'ра', '▁д', '▁по', '▁б', 'ро', '▁не', 'ка', 'ел', 'ре', '▁на', 'ть', 'ли', '▁т', 'во', '▁ч', 'ни', '▁у', 'ри', '▁е', '▁з', 'ло', 'ны', 'ся', 'ер', 'на', 'ет', 'ла', 'да', 'ва', '▁бы', 'ем', '▁ка', 'не', '▁ко', '▁э', 'сь', 'ки', 'ль', 'ми', '▁то', '▁к', 'ени', 'ру', '▁за', '▁ж', '▁что', 'ти', 'е,', '▁я', 'ди', 'до', 'ви', 'хо', 'ле', '▁от', '▁во', '▁со', '▁ра', '▁при', '▁он', '▁вс', '▁это', 'та', '▁мо', '▁до', 'ну', 'му', 'мо', '▁про', 'ей', 'чи', 'вал', '▁его', 'ве', '▁та', 'по', 'бо', '▁г', 'ля', 'ры', 'сти', 'ши', 'м,', 'сть', '▁как', '▁—', 'тел', '▁ни', 'сто', '▁го', 'лу', '▁все', '▁об', 'енно', 'ере', 'гда', 'же', '▁ст', '▁сво', 'ча', '▁вы', 'де', '▁из', '▁но', 'че', '▁а', 'й,', 'лю', 'ма', 'ще', '▁пре', '▁Н', '▁бо', 'ше', 'я,', 'ду', 'за', 'ку', '▁О', '▁кото', 'ста', 'еб', 'али', '▁ли', '▁В', 'ме', 'тель', '▁раз', 'дел', 'ной', 'ня', '▁К', '▁хо', 'со', 'ство', 'ги', '▁са', 'ско', 'жи', 'вы', 'лся', '▁жи', 'ало', '▁бе', 'си', '▁мен', 'щи', '▁ве', 'ело', '▁было', '▁дру', '▁И', 'ного', '▁П', '▁мне', 'ень', 'ться', 'бы', 'ств', 'га', 'енны', 'аль', '▁лю', '▁—\\xa0', 'лько', 'вер', 'ды', '\\xa0—', '-то', '▁был', 'ть,', 'уд', 'ала', '▁так', 'кой', 'ря', 'шь', 'каз', '▁же', '▁под', '▁ми', '▁меня', 'би', '▁Г', '▁ду', '▁Т', '▁да', '▁С', '▁М', '▁ви', 'ша', 'ты', '▁ста', 'вет', 'рем', 'те', 'са', 'но,', 'ца', 'мы', '▁себ', '▁си', 'лы', 'х,', 'ели', '▁пере', '▁ис', 'ха', '▁те', '▁ему', '▁од', 'пи', '▁или', 'ски', '▁еще', 'у,', '▁ме', '▁когда', '▁ма', '▁мы', '▁пос', '▁Я', 'ю,', '▁которы', '▁ре', 'па', 'ения', 'ным', '▁она', 'жа', '▁боль', '▁сто', '▁жиз', 'ение', '▁зна', 'раз', 'сли', 'ный', '▁ее', 'жно', '▁чу', 'сь,', '▁стра', 'нь', 'ные', '▁ты', '▁воз', '▁Он', 'ми,', 'зы', 'ела', 'ту', '▁для', '▁ц', '▁Д', '▁Но', '▁ле', 'ком', 'вши', 'ался', 'ву', 'гу', 'в,', '▁рас', 'вно', '▁уже', '▁врем', '▁ро', 'ных', '▁ча', '▁без', 'ци', '▁ф', 'тельно', '▁«', 'ется', '▁только', 'его', 'е.', 'ерь', 'т,', '▁Б', '▁слу', 'ства', '▁пу', '▁су', 'м.', '▁му', 'го,', 'к,', '▁ва', '▁вз', 'про', '▁само', 'ная', '▁ру', '▁пред', '▁дол', 'ем,', 'елове', '▁эти', 'об', 'чно', 'ходи', '▁теб', 'мер', 'стви', 'се', 'вя', 'шел', '▁чем', '▁сло', '▁А', '▁которо', '▁челове', 'ща', '▁х', 'зна', 'жд', 'и,', 'вать', '▁гла', '▁чтобы', 'ка,', '▁По', '▁свои', 'нов', 'нно', 'ба', '▁была', 'це', 'ют', 'дин', 'ную', 'ал,', '▁–']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:28:00.401753Z",
          "start_time": "2019-11-05T18:27:59.731680Z"
        },
        "id": "ko2WdTUGpyEc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "33a14c50-3dfb-4fd0-e8cf-81ed52de2c92"
      },
      "source": [
        "plt.hist([len(sent) for sent in train_tokenized_sample], bins=30)\n",
        "plt.title('Distribution of tokenized fragment length')\n",
        "plt.yscale('log');"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:28:01.153867Z",
          "start_time": "2019-11-05T18:28:00.404320Z"
        },
        "id": "rBRwKqkxpyEc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "c1c10bd2-8916-467c-8567-379c6e1ac293"
      },
      "source": [
        "token_counts = np.bincount([token_id for chunk in val_tokenized_sample for token_id in chunk])\n",
        "\n",
        "plt.hist(token_counts, bins=100)\n",
        "plt.title('Tokens mention distribution')\n",
        "plt.yscale('log');"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZRepDx8pyEd"
      },
      "source": [
        "## Creation of [datasets](#scrollTo=OYs7y8NkMDFJ&line=8&uniqifier=1) for PyTorch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:28:02.980335Z",
          "start_time": "2019-11-05T18:28:02.938616Z"
        },
        "id": "K73PIdFHpyEd"
      },
      "source": [
        "CHUNK_LENGTH = 200\n",
        "\n",
        "train_dataset = LanguageModelDataset(train_tokenized_sample,\n",
        "                                     chunk_length=CHUNK_LENGTH)\n",
        "val_dataset = LanguageModelDataset(val_tokenized_sample,\n",
        "                                    chunk_length=CHUNK_LENGTH)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEeDgemizvda"
      },
      "source": [
        "## Finding the appropriate batch size for train and validation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8I125zlqxQu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b02115ac-642a-46c5-c395-d2280db10fe1"
      },
      "source": [
        "print(f\"divisors of train dataset size ({len(train_dataset)}) are {divisors(len(train_dataset))}\")\r\n",
        "print(f\"divisors of val dataset size ({len(val_dataset)}) are {divisors(len(val_dataset))}\")\r\n",
        "\r\n",
        "batch_size_train = 66\r\n",
        "batch_size_val = 9"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "divisors of train dataset size (11946) are [1, 2, 3, 6, 11, 22, 33, 66, 181, 362, 543, 1086, 1991, 3982, 5973, 11946]\n",
            "divisors of val dataset size (5121) are [1, 3, 9, 569, 1707, 5121]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-aOq3AKpyEh"
      },
      "source": [
        "## Using PyTorchEncoderLayer and our [LanguageModel class](#scrollTo=QZBmKyALZ5lq&line=1&uniqifier=1) for model creation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:28:10.550078Z",
          "start_time": "2019-11-05T18:28:10.425261Z"
        },
        "id": "KzZcp4K9pyEi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6beda764-a40b-4ab5-9cba-76a15101954e"
      },
      "source": [
        "EMB_SIZE = 300             # if use BPEmb: SUPPORTED_DIMS = [25, 50, 100, 200, 300]\n",
        "HEADS_NUMBER = 15\n",
        "DIM_FEEDFORWARD = 500\n",
        "LAYERS_NUMBER = 8\n",
        "EMB_DROPOUT = 0.1\n",
        "LAYER_DROPOUT = 0.1\n",
        "\n",
        "vectors = BPEmb(language='ru', dim=EMB_SIZE,  merge_ops=min([1000, 3000, 5000, 10000, 25000, 50000, 100000, 200000], key=lambda x:abs(x-tokenizer.vocab_size())))\n",
        "emb_weights = vectors[tokenizer.vocab()]\n",
        "\n",
        "TransformerEncoderLayer = nn.TransformerEncoderLayer(d_model=EMB_SIZE, nhead=HEADS_NUMBER, dim_feedforward=DIM_FEEDFORWARD, dropout=LAYER_DROPOUT, activation='gelu')\n",
        "\n",
        "backbone = BatchFirstTransformerEncoder(TransformerEncoderLayer, num_layers=LAYERS_NUMBER)\n",
        "\n",
        "torch_transf_model = LanguageModel(vocab_size=tokenizer.vocab_size(), emb_size=EMB_SIZE, backbone=backbone, emb_weights=emb_weights, freeze=False, emb_dropout=EMB_DROPOUT)\n",
        "\n",
        "print('Number of parameters in model:', get_params_number(torch_transf_model))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of parameters in model: 5606100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab9_bB2Quild"
      },
      "source": [
        "## [Training](#scrollTo=jx44W288jjRP&line=1&uniqifier=1):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:28:58.797642Z",
          "start_time": "2019-11-05T18:28:34.626744Z"
        },
        "id": "evcA3YG3pyEi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 670
        },
        "outputId": "b7b0b0db-399c-4db5-9a9a-f0ff5a86f8b4"
      },
      "source": [
        "lr_scheduler = lambda optim: \\\n",
        "    torch.optim.lr_scheduler.ReduceLROnPlateau(optim, patience=5, factor=0.75, verbose=True)\n",
        "\n",
        "#lr_scheduler = lambda optim: \\\n",
        "#    torch.optim.lr_scheduler.StepLR(optim, step_size=5, gamma=0.9)\n",
        "\n",
        "best_val_loss, best_torch_transf_model = train_eval_loop(torch_transf_model,\n",
        "                                                         train_dataset,\n",
        "                                                         val_dataset,\n",
        "                                                         lm_cross_entropy,\n",
        "                                                         lr=2e-4,\n",
        "                                                         epoch_n=300,\n",
        "                                                         batch_size_train=batch_size_train,\n",
        "                                                         batch_size_val=batch_size_val,\n",
        "                                                         device='cuda',\n",
        "                                                         early_stopping_patience=15,\n",
        "                                                         lr_scheduler_ctor=lr_scheduler,\n",
        "                                                         draw_loss=True,\n",
        "                                                         dataloader_workers_n=5)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "mean loss\n",
            "\ttraining         \t (min:    2.186, max:    5.608, cur:    2.186)\n",
            "\tvalidation       \t (min:    2.354, max:    5.566, cur:    2.354)\n",
            "\n",
            "Stopped early by user\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CptBPDz8tWxd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "0b303fee-d4c6-4349-af50-3ee6b54f1038"
      },
      "source": [
        "MODEL_FILENAME = f\"/tmp/best_torch_transf_model_{best_val_loss}.pth\"\r\n",
        "torch.save(best_torch_transf_model.state_dict(), MODEL_FILENAME)\r\n",
        "files.download(MODEL_FILENAME)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_43e6fe83-f462-47ec-b80a-654957b2b643\", \"best_torch_transf_model_2.3536726498226708.pth\", 22459965)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDOJilyxpyEk"
      },
      "source": [
        "## Text generation using language modeling:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vtput-CmpyEk"
      },
      "source": [
        "### Greedy generation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaByhfwC42j9"
      },
      "source": [
        "MAX_STEPS = 100"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:29:02.366423Z",
          "start_time": "2019-11-05T18:29:02.329495Z"
        },
        "id": "U-TVEKzYpyEl"
      },
      "source": [
        "greedy_generator = GreedyGenerator(best_torch_transf_model, tokenizer)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:29:03.175509Z",
          "start_time": "2019-11-05T18:29:02.921960Z"
        },
        "id": "AkmVKww6pyEl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1a3a4ab-4007-411b-d4c0-d257239f3c8b"
      },
      "source": [
        "print(greedy_generator('Многие испытывают то умирание и рождение заново, какое представляет собой наша судьба, ', max_steps_n=MAX_STEPS)) # Демиан"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Многие испытывают то умирание и рождение заново, какое представляет собой наша судьба, какое-то время от времени, какое-то время от времени прошлого, какое-то время от времени прошлого, какое-то время от времени, какое-то время от времени прошлого, какое-то время от времени прошлого, какое-то время от времени прошлого, какое-то время от времени прошлого, како\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:29:03.497702Z",
          "start_time": "2019-11-05T18:29:03.177598Z"
        },
        "id": "jvrdj553pyEl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "664293c4-8d30-4fb2-9caf-0822926723ea"
      },
      "source": [
        "print(greedy_generator('Чрезмерное знание, слишком много священных стихов, слишком много жертвенных правил, ', max_steps_n=MAX_STEPS)) # Сиддхартха"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Чрезмерное знание, слишком много священных стихов, слишком много жертвенных правил, слишком много настоящего. Если бы я, наверно, слишком много способности к нему, то я, чтобы он был, чтобы он, слишком много раз, чтобы они были слишком многообещающими. Но, слишком много, слишком много способностей, слишком\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:29:03.770265Z",
          "start_time": "2019-11-05T18:29:03.500330Z"
        },
        "id": "tDaXIIG0pyEm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "063f2972-8cd0-427b-d6a9-cc3f7bb5eaf0"
      },
      "source": [
        "print(greedy_generator('В ее глазах, холодных и светлых, витала умудренная грусть, эти глаза, казалось, выстрадали все мыслимые страданья и сказали им «да». ', max_steps_n=MAX_STEPS)) # Степной волк"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "В ее глазах, холодных и светлых, витала умудренная грусть, эти глаза, казалось, выстрадали все мыслимые страданья и сказали им «да». Любовь к нему я видел, как красивый мужчина, и, подобно тому как он, как я, как он, как всякое время. Если бы я снова и снова увидел, как всякий раз, когда я, снова и снова и снова, снова и снова, снова и с\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyEFB9JXpyEm"
      },
      "source": [
        "### Generation using beam search:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:29:08.328662Z",
          "start_time": "2019-11-05T18:29:08.294006Z"
        },
        "id": "JL_cnQ-WpyEn"
      },
      "source": [
        "beam_generator = BeamGenerator(best_torch_transf_model, tokenizer)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-11-05T18:29:10.573399Z",
          "start_time": "2019-11-05T18:29:09.653198Z"
        },
        "id": "ub9oEWgSpyEn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e34baf5-0556-4c97-8998-20bd27a9e99a"
      },
      "source": [
        "%%time\n",
        "\n",
        "beam_gen_variants = beam_generator('Многие испытывают то умирание и рождение заново, какое представляет собой наша судьба, ', max_steps_n=MAX_STEPS, beamsize=5, return_hypotheses_n=5)\n",
        "\n",
        "for score, pred_txt in beam_gen_variants:\n",
        "    print('****')\n",
        "    print(score)\n",
        "    print(pred_txt)\n",
        "    print()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "****\n",
            "6.8797614035957\n",
            "Многие испытывают то умирание и рождение заново, какое представляет собой наша судьба, какое-то время от времени, какое-то время от времени прошлого, какое-то время от времени прошлого, какое-то время от времени, каким-то особенно сделалось нечто совсем необыкновенное, что-то от нее и неправильное. Кнехт почувствовал, что-то недо\n",
            "\n",
            "****\n",
            "6.894255700261887\n",
            "Многие испытывают то умирание и рождение заново, какое представляет собой наша судьба, какое-то время от времени, какое-то время от времени прошлого, какое-то время от времени прошлого, какое-то время от времени, каким-то особенно сделалось нечто совсем необыкновенное, что-то от нее и неправильное. Кнехт почувствовал, что-то неи\n",
            "\n",
            "****\n",
            "6.909667867544825\n",
            "Многие испытывают то умирание и рождение заново, какое представляет собой наша судьба, какое-то время от времени, какое-то время от времени прошлого, какое-то время от времени прошлого, какое-то время от времени, каким-то особенно сделалось нечто совсем необыкновенное, что-то от нее и неправильное. Кнехт почувствовал, что-то неда\n",
            "\n",
            "****\n",
            "6.934414615235442\n",
            "Многие испытывают то умирание и рождение заново, какое представляет собой наша судьба, какое-то время от времени, какое-то время от времени прошлого, какое-то время от времени прошлого, какое-то время от времени, каким-то особенно сделалось нечто совсем необыкновенное, что-то от нее и неправильное, что-то от нее и неправильное, что-то\n",
            "\n",
            "****\n",
            "6.954535526510309\n",
            "Многие испытывают то умирание и рождение заново, какое представляет собой наша судьба, какое-то время от времени, какое-то время от времени прошлого, какое-то время от времени прошлого, какое-то время от времени, каким-то особенно сделалось нечто совсем необыкновенное, что-то от нее и неправильное. Кнехт почувствовал, что-то не в\n",
            "\n",
            "CPU times: user 4.12 s, sys: 49.5 ms, total: 4.17 s\n",
            "Wall time: 4.17 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOIvG6fw5d3V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "911c0f84-1091-402e-b184-a1defa73c5a0"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "beam_gen_variants = beam_generator('Чрезмерное знание, слишком много священных стихов, слишком много жертвенных правил, ', max_steps_n=MAX_STEPS, beamsize=5, return_hypotheses_n=5)\r\n",
        "\r\n",
        "for score, pred_txt in beam_gen_variants:\r\n",
        "    print('****')\r\n",
        "    print(score)\r\n",
        "    print(pred_txt)\r\n",
        "    print()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "****\n",
            "5.232607874028768\n",
            "Чрезмерное знание, слишком много священных стихов, слишком много жертвенных правил, слишком много напряжений и слишком много нарочито, слишком много способностей, слишком много нарочито, слишком много народов, слишком много народов, слишком много народов, слишком много народов, слишком много насчет то\n",
            "\n",
            "****\n",
            "5.254232214295294\n",
            "Чрезмерное знание, слишком много священных стихов, слишком много жертвенных правил, слишком много напряжений и слишком много нарочито, слишком много способностей, слишком много нарочито, слишком много народов, слишком много народов, слишком много народов, слишком много народов, слишком много насчет и\n",
            "\n",
            "****\n",
            "5.258527455031281\n",
            "Чрезмерное знание, слишком много священных стихов, слишком много жертвенных правил, слишком много напряжений и слишком много нарочито, слишком много способностей, слишком много нарочито, слишком много народов, слишком много народов, слишком много народов, слишком много народов, слишком много насчет г\n",
            "\n",
            "****\n",
            "5.28050376974828\n",
            "Чрезмерное знание, слишком много священных стихов, слишком много жертвенных правил, слишком много напряжений и слишком много нарочито, слишком много способностей, слишком много нарочито, слишком много народов, слишком много народов, слишком много народов, слишком много народов, слишком много насчет с\n",
            "\n",
            "****\n",
            "5.282815132664173\n",
            "Чрезмерное знание, слишком много священных стихов, слишком много жертвенных правил, слишком много напряжений и слишком много нарочито, слишком много способностей, слишком много нарочито, слишком много народов, слишком много народов, слишком много народов, слишком много народов, слишком много насчет,\n",
            "\n",
            "CPU times: user 4.74 s, sys: 66.6 ms, total: 4.8 s\n",
            "Wall time: 4.81 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDy1tHkL5mBf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87cbbd85-7a2c-4548-e26d-c5eab74d788f"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "beam_gen_variants = beam_generator('В ее глазах, холодных и светлых, витала умудренная грусть, эти глаза, казалось, выстрадали все мыслимые страданья и сказали им «да». ', max_steps_n=MAX_STEPS, beamsize=5, return_hypotheses_n=5)\r\n",
        "\r\n",
        "for score, pred_txt in beam_gen_variants:\r\n",
        "    print('****')\r\n",
        "    print(score)\r\n",
        "    print(pred_txt)\r\n",
        "    print()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "****\n",
            "8.029404517022474\n",
            "В ее глазах, холодных и светлых, витала умудренная грусть, эти глаза, казалось, выстрадали все мыслимые страданья и сказали им «да». И все-таки этот смерть, казалось, звучалось так же необычно. Лишь смех и смеялся над ней и смотрел на него. — Вот как? — спросил я. — Не знаю, — сказал я. — Я не могу сказать ничего другого. — Нет, ничего.\n",
            "\n",
            "****\n",
            "8.084295742987306\n",
            "В ее глазах, холодных и светлых, витала умудренная грусть, эти глаза, казалось, выстрадали все мыслимые страданья и сказали им «да». И все-таки этот смерть, казалось, звучалось так же необычно. Лишь смех и смеялся над ней и смотрел на него. — Вот как? — спросил я. — Не знаю, — сказал я. — Я не могу сказать ничего другого. — Нет, ничего не\n",
            "\n",
            "****\n",
            "8.121333367071816\n",
            "В ее глазах, холодных и светлых, витала умудренная грусть, эти глаза, казалось, выстрадали все мыслимые страданья и сказали им «да». И все-таки этот смерть, казалось, звучалось так же необычно. Лишь смех и смеялся над ней и смотрел на него. — Вот как? — спросил я. — Не знаю, — сказал я. — Я не могу сказать ничего другого. — Ты скажу.\n",
            "\n",
            "****\n",
            "8.143001600129598\n",
            "В ее глазах, холодных и светлых, витала умудренная грусть, эти глаза, казалось, выстрадали все мыслимые страданья и сказали им «да». И все-таки этот смерть, казалось, звучалось так же необычно. Лишь смех и смеялся над ней и смотрел на него. — Вот как? — спросил я. — Не знаю, — сказал я. — Я не могу сказать ничего другого. — Ты скажу, —\n",
            "\n",
            "****\n",
            "8.157109921478263\n",
            "В ее глазах, холодных и светлых, витала умудренная грусть, эти глаза, казалось, выстрадали все мыслимые страданья и сказали им «да». И все-таки этот смерть, казалось, звучалось так же необычно. Лишь смех и смеялся над ней и смотрел на него. — Вот как? — спросил я. — Не знаю, — сказал я. — Я не могу сказать ничего другого. — Нет, ничего дру\n",
            "\n",
            "CPU times: user 4.45 s, sys: 60.1 ms, total: 4.51 s\n",
            "Wall time: 4.51 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNows2lqI7Gh"
      },
      "source": [
        "prob_generator = ProbGenerator(best_torch_transf_model, tokenizer, max_steps_n=MAX_STEPS, temperature=0.75)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQZ9vrw6F4fn",
        "outputId": "783ccf39-372c-454b-c589-922b396ed0da"
      },
      "source": [
        "print(prob_generator('Многие испытывают то умирание и рождение заново, какое представляет собой наша судьба, '))"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Многие испытывают то умирание и рождение заново, какое представляет собой наша судьба, какая-то религия как эта. Вот имеет много неприятных. Согласно знает, что об этом и нет. Всегда именно это я еще стоял как обиду, надо полагать, что способность утонченность и снова принимали письмо читатели при это\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-xibYuzF-7h",
        "outputId": "bded9fb6-abf7-4058-e63e-45105f88b601"
      },
      "source": [
        "print(prob_generator('Чрезмерное знание, слишком много священных стихов, слишком много жертвенных правил, '))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Чрезмерное знание, слишком много священных стихов, слишком много жертвенных правил, слишком много было то, что для него за него ничего не удавалось, слишком много лжи. Старик дружил некоторое время поиски, и, пожалуй, слишком много спрашивал. Он показался мне и вошел в свою комнату. Совершенно мне приходилось стать\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wMOzxxMGg51",
        "outputId": "6f983be3-bd29-48ba-ef88-39dfcfd12ec0"
      },
      "source": [
        "print(prob_generator('В ее глазах, холодных и светлых, витала умудренная грусть, эти глаза, казалось, выстрадали все мыслимые страданья и сказали им «да». ')) # Степной волк"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "В ее глазах, холодных и светлых, витала умудренная грусть, эти глаза, казалось, выстрадали все мыслимые страданья и сказали им «да». Между тем молча вовсе не было колдовством, с которым здесь отдалилась от родины, и на это полуопискалось бы из Провинции и критиковые дела, изменялись, по возможности выдумчиво успеха, и они проглядывали у них в\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}